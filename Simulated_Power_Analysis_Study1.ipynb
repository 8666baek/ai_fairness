{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_candidate_pair_data(n_pairs_per_treatment):\n",
    "    \"\"\"\n",
    "    Generate realistic paired comparison data based on actual hiring statistics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_pairs_per_treatment : int\n",
    "        Number of candidate pairs per treatment condition\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of candidate pairs with attribute differences\n",
    "    \"\"\"\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    for pair_id in range(n_pairs_per_treatment):\n",
    "        # Generate two candidates based on actual hiring data distributions\n",
    "        candidates = []\n",
    "        \n",
    "        for candidate_num in range(2):\n",
    "            # Basic demographics (from summary stats)\n",
    "            female = np.random.binomial(1, 0.5)\n",
    "            \n",
    "            # Internship experience\n",
    "            internship_exp = np.random.binomial(1, 0.483)\n",
    "            \n",
    "            # Certificates (0-4, following actual distribution)\n",
    "            certificates = np.random.choice(range(5), p=[0.1, 0.25, 0.25, 0.25, 0.15])\n",
    "            \n",
    "            # University ranking (simplified to numeric for easier difference calculation)\n",
    "            # Higher values = better universities, based on regression coefficients\n",
    "            university_values = {\n",
    "                'etc': 0,  # baseline\n",
    "                'domestic_top14_22': 0.897,\n",
    "                'international_middle_low': 1.136,\n",
    "                'domestic_top10_13': 1.309,\n",
    "                'domestic_top9_female': 1.400,\n",
    "                'domestic_top6_8': 1.881,\n",
    "                'domestic_top4_5': 2.348,\n",
    "                'international_high': 2.525,\n",
    "                'domestic_top3': 3.525\n",
    "            }\n",
    "            university_categories = list(university_values.keys())\n",
    "            university_probs = [0.35, 0.05, 0.02, 0.18, 0.02, 0.15, 0.12, 0.03, 0.08]\n",
    "            university_cat = np.random.choice(university_categories, p=university_probs)\n",
    "            university_score = university_values[university_cat]\n",
    "            \n",
    "            # GPA (from summary stats, no quadratic term)\n",
    "            gpa = np.random.normal(80.934, 7.489)\n",
    "            gpa = np.clip(gpa, 36.4, 100.0)\n",
    "            \n",
    "            candidates.append({\n",
    "                'female': female,\n",
    "                'internship_exp': internship_exp,\n",
    "                'certificates': certificates,\n",
    "                'university_score': university_score,\n",
    "                'gpa': gpa\n",
    "            })\n",
    "        \n",
    "        # Calculate differences (Candidate 1 - Candidate 2)\n",
    "        delta_gender = (1 - candidates[0]['female']) - (1 - candidates[1]['female'])  # male=1, female=0\n",
    "        delta_internship_exp = candidates[0]['internship_exp'] - candidates[1]['internship_exp']\n",
    "        delta_certificates = candidates[0]['certificates'] - candidates[1]['certificates']\n",
    "        delta_university = candidates[0]['university_score'] - candidates[1]['university_score']\n",
    "        delta_gpa = candidates[0]['gpa'] - candidates[1]['gpa']\n",
    "        \n",
    "        pairs.append({\n",
    "            'pair_id': pair_id,\n",
    "            'delta_gender': delta_gender,  # 1 if first is male and second is female, -1 if opposite, 0 if same\n",
    "            'delta_internship_exp': delta_internship_exp,\n",
    "            'delta_certificates': delta_certificates,\n",
    "            'delta_university': delta_university,\n",
    "            'delta_gpa': delta_gpa,\n",
    "            'candidate1': candidates[0],\n",
    "            'candidate2': candidates[1]\n",
    "        })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def calculate_selection_probability(pair_data, treatment, is_individualism, effect_sizes, participant_random_effect):\n",
    "    \"\"\"\n",
    "    Calculate probability of selecting first candidate based on attribute differences\n",
    "    Using coefficients adapted from actual hiring data for paired comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base coefficients adapted for paired comparison\n",
    "    # Baseline gender bias corresponds to OR=1.72 (log(1.72) ≈ 0.542)\n",
    "    coefficients = {\n",
    "        'intercept': 0,  # No intercept in paired comparison (symmetric)\n",
    "        'gender': 1.519,  # OR=1.72 baseline gender bias (updated from 1.519)\n",
    "        'internship_exp': 0.360,\n",
    "        'certificates': 0.169,\n",
    "        'university': 1.0,  # Coefficient per unit university score difference\n",
    "        'gpa': 0.335/10   # Original was per unit GPA, adjusted for typical GPA differences\n",
    "    }\n",
    "    \n",
    "    # Base log odds from attribute differences\n",
    "    log_odds = coefficients['intercept']\n",
    "    log_odds += coefficients['gender'] * pair_data['delta_gender']\n",
    "    log_odds += coefficients['internship_exp'] * pair_data['delta_internship_exp']\n",
    "    log_odds += coefficients['certificates'] * pair_data['delta_certificates']\n",
    "    log_odds += coefficients['university'] * pair_data['delta_university']\n",
    "    log_odds += coefficients['gpa'] * pair_data['delta_gpa']\n",
    "    \n",
    "    # Add consistent participant random effect\n",
    "    log_odds += participant_random_effect\n",
    "    \n",
    "    # Treatment effects on gender preference (2-way interactions)\n",
    "    if treatment == 'T0_unfair':\n",
    "        # H1B: Unfair AI amplifies gender bias\n",
    "        log_odds += effect_sizes['unfair_gender_interaction'] * pair_data['delta_gender']\n",
    "    elif treatment == 'T1_group_fair':\n",
    "        # H1A: Group fairness AI reduces gender bias\n",
    "        log_odds += effect_sizes['group_fair_gender_interaction'] * pair_data['delta_gender']\n",
    "    elif treatment == 'T2_individual_fair':\n",
    "        # H1A: Individual fairness AI reduces gender bias\n",
    "        log_odds += effect_sizes['individual_fair_gender_interaction'] * pair_data['delta_gender']\n",
    "    \n",
    "    # 3-way interactions (culture moderates AI effects on gender bias)\n",
    "    if treatment == 'T0_unfair' and is_individualism:\n",
    "        # Culture effect on unfair AI (no specific hypothesis)\n",
    "        log_odds += effect_sizes['culture_unfair_gender'] * pair_data['delta_gender']\n",
    "    elif treatment == 'T1_group_fair' and is_individualism:\n",
    "        # H3B: In individualist cultures, group fairness may be less effective\n",
    "        log_odds += effect_sizes['culture_group_gender'] * pair_data['delta_gender']\n",
    "    elif treatment == 'T2_individual_fair' and is_individualism:\n",
    "        # H3A: In individualist cultures, individual fairness is more effective\n",
    "        log_odds += effect_sizes['culture_individual_gender'] * pair_data['delta_gender']\n",
    "    \n",
    "    # Convert to probability\n",
    "    prob = 1 / (1 + np.exp(-log_odds))\n",
    "    return np.clip(prob, 1e-10, 1-1e-10)\n",
    "\n",
    "def generate_study1_data(n_participants, pairs_per_treatment, effect_sizes):\n",
    "    \"\"\"\n",
    "    Generate data for Study 1 with consistent participant random effects\n",
    "    \"\"\"\n",
    "    data_rows = []\n",
    "    treatments = ['control', 'T0_unfair', 'T1_group_fair', 'T2_individual_fair']\n",
    "    \n",
    "    # Generate participant random effects (consistent across all conditions for each participant)\n",
    "    sigma_within = np.pi**2 / 3 \n",
    "    target_icc = 0.25\n",
    "    sigma_participant = np.sqrt(target_icc * sigma_within / (1 - target_icc)) \n",
    "\n",
    "    participant_random_effects = {}\n",
    "    for participant_id in range(n_participants):\n",
    "        participant_random_effects[participant_id] = np.random.normal(0, sigma_participant)\n",
    "    \n",
    "    for participant_id in range(n_participants):\n",
    "        # Assign participant's cultural orientation (fixed for participant)\n",
    "        is_individualism = np.random.binomial(1, 0.5)\n",
    "        \n",
    "        # Each participant evaluates pairs in all treatment conditions\n",
    "        for treatment in treatments:\n",
    "            # Generate candidate pairs for this treatment\n",
    "            pairs = generate_candidate_pair_data(pairs_per_treatment)\n",
    "            \n",
    "            for pair in pairs:\n",
    "                # Calculate selection probability using consistent random effect\n",
    "                prob = calculate_selection_probability(\n",
    "                    pair, treatment, is_individualism, effect_sizes,\n",
    "                    participant_random_effects[participant_id]\n",
    "                )\n",
    "                \n",
    "                # Generate binary choice (1 = select first candidate, 0 = select second)\n",
    "                y = np.random.binomial(1, prob)\n",
    "                \n",
    "                data_rows.append({\n",
    "                    'y': y,\n",
    "                    'delta_gender': pair['delta_gender'],\n",
    "                    'delta_internship_exp': pair['delta_internship_exp'],\n",
    "                    'delta_certificates': pair['delta_certificates'],\n",
    "                    'delta_university': pair['delta_university'],\n",
    "                    'delta_gpa': pair['delta_gpa'],\n",
    "                    'treatment': treatment,\n",
    "                    'is_individualism': is_individualism,\n",
    "                    'participant_id': participant_id,\n",
    "                    'pair_id': f\"{participant_id}_{treatment}_{pair['pair_id']}\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data_rows)\n",
    "\n",
    "def test_hypothesis_h1a(df, alpha=0.05):\n",
    "    \"\"\"Test H1A: Fair AI reduces gender bias (group + individual fairness vs control)\"\"\"\n",
    "    try:\n",
    "        # Create treatment dummy variables\n",
    "        df_test = pd.get_dummies(df, columns=['treatment'], prefix='T', drop_first=False)\n",
    "        df_test = df_test.drop(columns=['T_control'])  # Control as reference\n",
    "        \n",
    "        # Convert to float\n",
    "        for col in ['T_T0_unfair', 'T_T1_group_fair', 'T_T2_individual_fair']:\n",
    "            df_test[col] = df_test[col].astype(float)\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa +\n",
    "              T_T0_unfair + T_T1_group_fair + T_T2_individual_fair + \n",
    "              delta_gender:T_T0_unfair + delta_gender:T_T1_group_fair + delta_gender:T_T2_individual_fair\n",
    "        \"\"\"\n",
    "\n",
    "        model = logit(formula, data=df_test).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_test['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test if fair AI reduces bias (negative interactions)\n",
    "        fair_interactions = ['delta_gender:T_T1_group_fair', 'delta_gender:T_T2_individual_fair']\n",
    "        p_vals = [model.pvalues.get(term, 1.0) for term in fair_interactions if term in model.pvalues]\n",
    "        coefficients = [model.params.get(term, 0.0) for term in fair_interactions if term in model.params]\n",
    "        \n",
    "        # H1A is supported if fair AI reduces bias (negative coef & significant)\n",
    "        return any(p < alpha and coef < 0 for p, coef in zip(p_vals, coefficients))\n",
    "\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h1b(df, alpha=0.05):\n",
    "    \"\"\"Test H1B: Unfair AI amplifies gender bias\"\"\"\n",
    "    try:\n",
    "        # Create treatment dummy variables\n",
    "        df_test = pd.get_dummies(df, columns=['treatment'], prefix='T', drop_first=False)\n",
    "        df_test = df_test.drop(columns=['T_control'])  # Control as reference\n",
    "        \n",
    "        # Convert to float\n",
    "        for col in ['T_T0_unfair', 'T_T1_group_fair', 'T_T2_individual_fair']:\n",
    "            df_test[col] = df_test[col].astype(float)\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa +\n",
    "              T_T0_unfair + T_T1_group_fair + T_T2_individual_fair + \n",
    "              delta_gender:T_T0_unfair + delta_gender:T_T1_group_fair + delta_gender:T_T2_individual_fair\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_test).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_test['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test if unfair AI amplifies bias (positive interaction)\n",
    "        if 'delta_gender:T_T0_unfair' in model.pvalues:\n",
    "            p_val = model.pvalues['delta_gender:T_T0_unfair']\n",
    "            coef = model.params['delta_gender:T_T0_unfair']\n",
    "            return (p_val < alpha) and (coef > 0)  # Positive = amplifies bias\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h2(df, alpha=0.05):\n",
    "    \"\"\"Test H2: Individual fairness more effective than Group fairness (directional hypothesis)\"\"\"\n",
    "    try:\n",
    "        # Create treatment dummy variables - use full dataset\n",
    "        df_test = pd.get_dummies(df, columns=['treatment'], prefix='T', drop_first=False)\n",
    "        df_test = df_test.drop(columns=['T_control'])  # Control as reference\n",
    "        \n",
    "        # Convert to float\n",
    "        for col in ['T_T0_unfair', 'T_T1_group_fair', 'T_T2_individual_fair']:\n",
    "            df_test[col] = df_test[col].astype(float)\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa +\n",
    "              T_T0_unfair + T_T1_group_fair + T_T2_individual_fair + \n",
    "              delta_gender:T_T0_unfair + delta_gender:T_T1_group_fair + delta_gender:T_T2_individual_fair\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_test).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_test['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # H2: Test if Individual fairness (δ₂) is more effective than Group fairness (δ₁)\n",
    "        # More effective means MORE negative coefficient (greater bias reduction)\n",
    "        # Test: δ₂ - δ₁ < 0, equivalent to δ₁ - δ₂ > 0\n",
    "        \n",
    "        if ('delta_gender:T_T1_group_fair' in model.params and \n",
    "            'delta_gender:T_T2_individual_fair' in model.params):\n",
    "            \n",
    "            # Get coefficients\n",
    "            delta_1 = model.params['delta_gender:T_T1_group_fair']  # Group fairness\n",
    "            delta_2 = model.params['delta_gender:T_T2_individual_fair']  # Individual fairness\n",
    "            \n",
    "            # Calculate difference (δ₁ - δ₂)\n",
    "            diff = delta_1 - delta_2\n",
    "            \n",
    "            # Get variance-covariance matrix\n",
    "            cov_matrix = model.cov_params()\n",
    "            var_delta_1 = cov_matrix.loc['delta_gender:T_T1_group_fair', 'delta_gender:T_T1_group_fair']\n",
    "            var_delta_2 = cov_matrix.loc['delta_gender:T_T2_individual_fair', 'delta_gender:T_T2_individual_fair']\n",
    "            cov_delta_1_2 = cov_matrix.loc['delta_gender:T_T1_group_fair', 'delta_gender:T_T2_individual_fair']\n",
    "            \n",
    "            # Standard error of difference\n",
    "            se_diff = np.sqrt(var_delta_1 + var_delta_2 - 2 * cov_delta_1_2)\n",
    "            \n",
    "            # Z-test for difference\n",
    "            z_stat = diff / se_diff\n",
    "            \n",
    "            # One-tailed test: H2 is supported if δ₁ - δ₂ > 0 (individual more effective)\n",
    "            p_val = 1 - stats.norm.cdf(z_stat)  # Upper tail\n",
    "            \n",
    "            return (p_val < alpha) and (diff > 0)\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_hypothesis_h3a(df, alpha=0.05):\n",
    "    \"\"\"Test H3A: Individual fairness is more effective in individualist cultures\"\"\"\n",
    "    try:\n",
    "        # Create treatment dummy variables\n",
    "        df_test = pd.get_dummies(df, columns=['treatment'], prefix='T', drop_first=False)\n",
    "        df_test = df_test.drop(columns=['T_control'])  # Control as reference\n",
    "        \n",
    "        # Convert to float\n",
    "        for col in ['T_T0_unfair', 'T_T1_group_fair', 'T_T2_individual_fair']:\n",
    "            df_test[col] = df_test[col].astype(float)\n",
    "        \n",
    "        # Full model with 3-way interactions\n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa +\n",
    "              T_T0_unfair + T_T1_group_fair + T_T2_individual_fair +\n",
    "              is_individualism +\n",
    "              delta_gender:T_T0_unfair + delta_gender:T_T1_group_fair + \n",
    "              delta_gender:T_T2_individual_fair +\n",
    "              delta_gender:is_individualism +\n",
    "              T_T0_unfair:is_individualism + T_T1_group_fair:is_individualism + \n",
    "              T_T2_individual_fair:is_individualism +\n",
    "              delta_gender:T_T0_unfair:is_individualism + \n",
    "              delta_gender:T_T1_group_fair:is_individualism +\n",
    "              delta_gender:T_T2_individual_fair:is_individualism\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_test).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_test['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test H3A: Individual fairness more effective in individualist cultures\n",
    "        # This means the 3-way interaction should be significantly NEGATIVE\n",
    "        # (individual fairness reduces bias MORE in individualist cultures)\n",
    "        interaction_term = 'delta_gender:T_T2_individual_fair:is_individualism'\n",
    "        \n",
    "        if interaction_term in model.pvalues:\n",
    "            p_val = model.pvalues[interaction_term]\n",
    "            coef = model.params[interaction_term]\n",
    "            return (p_val < alpha) and (coef < 0)  # Negative = more effective in individualist cultures\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h3b(df, alpha=0.05):\n",
    "    \"\"\"Test H3B: Group fairness is less effective in individualist cultures\"\"\"\n",
    "    try:\n",
    "        # Create treatment dummy variables\n",
    "        df_test = pd.get_dummies(df, columns=['treatment'], prefix='T', drop_first=False)\n",
    "        df_test = df_test.drop(columns=['T_control'])  # Control as reference\n",
    "        \n",
    "        # Convert to float\n",
    "        for col in ['T_T0_unfair', 'T_T1_group_fair', 'T_T2_individual_fair']:\n",
    "            df_test[col] = df_test[col].astype(float)\n",
    "        \n",
    "        # Full model with 3-way interactions\n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa +\n",
    "              T_T0_unfair + T_T1_group_fair + T_T2_individual_fair +\n",
    "              is_individualism +\n",
    "              delta_gender:T_T0_unfair + delta_gender:T_T1_group_fair + \n",
    "              delta_gender:T_T2_individual_fair +\n",
    "              delta_gender:is_individualism +\n",
    "              T_T0_unfair:is_individualism + T_T1_group_fair:is_individualism + \n",
    "              T_T2_individual_fair:is_individualism +\n",
    "              delta_gender:T_T0_unfair:is_individualism + \n",
    "              delta_gender:T_T1_group_fair:is_individualism +\n",
    "              delta_gender:T_T2_individual_fair:is_individualism\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_test).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_test['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test H3B: Group fairness less effective in individualist cultures\n",
    "        # This means the 3-way interaction should be significantly POSITIVE\n",
    "        # (group fairness reduces bias LESS in individualist cultures)\n",
    "        interaction_term = 'delta_gender:T_T1_group_fair:is_individualism'\n",
    "        \n",
    "        if interaction_term in model.pvalues:\n",
    "            p_val = model.pvalues[interaction_term]\n",
    "            coef = model.params[interaction_term]\n",
    "            return (p_val < alpha) and (coef > 0)  # Positive = less effective in individualist cultures\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def simulate_study1_power_analysis(n_participants_list, pairs_per_treatment, effect_sizes, n_sim=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Power analysis simulation for Study 1 hypotheses\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'n_participants': n_participants_list,\n",
    "        'power_h1a': [],  # Fair AI reduces bias\n",
    "        'power_h1b': [],  # Unfair AI amplifies bias  \n",
    "        'power_h2': [],   # Individual vs Group fairness\n",
    "        'power_h3a': [],  # H3A: Individual fairness more effective in individualist cultures\n",
    "        'power_h3b': [],  # H3B: Group fairness less effective in individualist cultures\n",
    "        'convergence_failures': [],\n",
    "        'exceptions': []\n",
    "    }\n",
    "    \n",
    "    print(\"Study 1 Power Analysis\")\n",
    "    print(f\"Pairs per treatment: {pairs_per_treatment}\")\n",
    "    print(\"Testing hypotheses:\")\n",
    "    print(\"  H1A: Fair AI reduces gender bias\")\n",
    "    print(\"  H1B: Unfair AI amplifies gender bias\")\n",
    "    print(\"  H2: Individual fairness MORE effective than Group fairness (directional)\")\n",
    "    print(\"  H3A: Individual fairness more effective in individualist cultures\")\n",
    "    print(\"  H3B: Group fairness less effective in individualist cultures\")\n",
    "    \n",
    "    for n in n_participants_list:\n",
    "        print(f\"\\nRunning simulation for {n} participants...\")\n",
    "        \n",
    "        power_counts = {'h1a': 0, 'h1b': 0, 'h2': 0, 'h3a': 0, 'h3b': 0}\n",
    "        convergence_fails = 0\n",
    "        exceptions = 0\n",
    "        \n",
    "        for sim in tqdm(range(n_sim), desc=f\"n={n}\", leave=False):\n",
    "            try:\n",
    "                # Generate data\n",
    "                df = generate_study1_data(n, pairs_per_treatment, effect_sizes)\n",
    "                \n",
    "                # Test each hypothesis\n",
    "                if test_hypothesis_h1a(df, alpha):\n",
    "                    power_counts['h1a'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h1b(df, alpha):\n",
    "                    power_counts['h1b'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h2(df, alpha):\n",
    "                    power_counts['h2'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h3a(df, alpha):\n",
    "                    power_counts['h3a'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h3b(df, alpha):\n",
    "                    power_counts['h3b'] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if \"Singular matrix\" in str(e) or \"convergence\" in str(e).lower():\n",
    "                    convergence_fails += 1\n",
    "                else:\n",
    "                    exceptions += 1\n",
    "                continue\n",
    "        \n",
    "        # Calculate power\n",
    "        valid_sims = n_sim - exceptions\n",
    "        \n",
    "        if valid_sims > 0:\n",
    "            results['power_h1a'].append(power_counts['h1a'] / valid_sims)\n",
    "            results['power_h1b'].append(power_counts['h1b'] / valid_sims)\n",
    "            results['power_h2'].append(power_counts['h2'] / valid_sims)\n",
    "            results['power_h3a'].append(power_counts['h3a'] / valid_sims)\n",
    "            results['power_h3b'].append(power_counts['h3b'] / valid_sims)\n",
    "        else:\n",
    "            results['power_h1a'].append(0)\n",
    "            results['power_h1b'].append(0)\n",
    "            results['power_h2'].append(0)\n",
    "            results['power_h3a'].append(0)\n",
    "            results['power_h3b'].append(0)\n",
    "            \n",
    "        results['convergence_failures'].append(convergence_fails / n_sim)\n",
    "        results['exceptions'].append(exceptions / n_sim)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_study1_power_curves(results, pairs_per_treatment):\n",
    "    \"\"\"Plot power curves for Study 1 hypotheses\"\"\"\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    hypotheses = [\n",
    "        ('power_h1a', 'H1A: Fair AI Reduces Gender Bias', 'blue'),\n",
    "        ('power_h1b', 'H1B: Unfair AI Amplifies Gender Bias', 'red'),\n",
    "        ('power_h2', 'H2: Individual > Group Fairness', 'green'),\n",
    "        ('power_h3a', 'H3A: Individual Fairness × Individualism', 'purple'),\n",
    "        ('power_h3b', 'H3B: Group Fairness × Individualism', 'orange')\n",
    "    ]\n",
    "    \n",
    "    for i, (power_key, title, color) in enumerate(hypotheses):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.plot(results['n_participants'], results[power_key], 'o-', \n",
    "                linewidth=2, markersize=6, color=color)\n",
    "        plt.axhline(0.8, color='orange', linestyle='--', alpha=0.7, label='Power = 0.8')\n",
    "        plt.axhline(0.95, color='red', linestyle='--', alpha=0.7, label='Power = 0.95')\n",
    "        plt.title(f'{title}\\n({pairs_per_treatment} pairs per treatment)', fontsize=11)\n",
    "        plt.xlabel('Number of Participants')\n",
    "        plt.ylabel('Estimated Power')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def find_study1_sample_requirements(results, pairs_per_treatment):\n",
    "    \"\"\"Find sample size requirements for Study 1 hypotheses\"\"\"\n",
    "    \n",
    "    hypotheses = [\n",
    "        ('power_h1a', 'H1A: Fair AI Reduces Gender Bias'),\n",
    "        ('power_h1b', 'H1B: Unfair AI Amplifies Gender Bias'),\n",
    "        ('power_h2', 'H2: Individual vs Group Fairness'),\n",
    "        ('power_h3a', 'H3A: Individual Fairness × Individualism'),\n",
    "        ('power_h3b', 'H3B: Group Fairness × Individualism')\n",
    "    ]\n",
    "    \n",
    "    for target_power in [0.8, 0.95]:\n",
    "        print(f\"\\n=== {target_power*100}% Power Requirements ===\")\n",
    "        \n",
    "        for power_key, hypothesis_name in hypotheses:\n",
    "            found = False\n",
    "            for i, power in enumerate(results[power_key]):\n",
    "                if power >= target_power:\n",
    "                    n_participants = results['n_participants'][i]\n",
    "                    total_pairs = n_participants * pairs_per_treatment * 4  # 4 treatments\n",
    "                    print(f\"{hypothesis_name}: {n_participants} participants \"\n",
    "                          f\"({total_pairs:,} total pair evaluations)\")\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                max_n = max(results['n_participants'])\n",
    "                max_power = max(results[power_key])\n",
    "                print(f\"{hypothesis_name}: >{max_n} participants needed \"\n",
    "                      f\"(max observed power: {max_power:.3f})\")\n",
    "\n",
    "# Example execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Experimental design parameters\n",
    "    pairs_per_treatment = 5  # Number of candidate pairs each participant evaluates per treatment\n",
    "    participants_range = list(range(25, 376, 50)) \n",
    "    \n",
    "    # Define effect sizes based on OR=1.72 baseline and expected effects\n",
    "    effect_sizes = {\n",
    "        # H1A: Fair AI reduces bias (OR = 1/1.72)\n",
    "        # H2\n",
    "        'group_fair_gender_interaction': -0.542,      # log(1/1.72) ≈ -0.542\n",
    "        'individual_fair_gender_interaction': -0.907, # Individual slightly more effective: cohen's d = 0.5, OR = 2.48\n",
    "        \n",
    "        # H1B: Unfair AI amplifies bias (OR = 1.72)  \n",
    "        'unfair_gender_interaction': 0.542,           # log(1.72) ≈ 0.542\n",
    "        \n",
    "        # H3A: Individual fairness more effective in individualist cultures (negative 3-way interaction)\n",
    "        'culture_individual_gender': -0.542,          # Individual fairness more effective in individualist cultures\n",
    "        \n",
    "        # H3B: Group fairness less effective in individualist cultures (positive 3-way interaction)\n",
    "        'culture_group_gender': 0.542,                # Group fairness less effective in individualist cultures  \n",
    "        \n",
    "        # Control for unfair AI cultural interaction (no specific hypothesis)\n",
    "        'culture_unfair_gender': 0,                   # No specific hypothesis for unfair AI\n",
    "    }\n",
    "    \n",
    "    print(\"=== STUDY 1 POWER ANALYSIS ===\")\n",
    "    print(f\"Participants range: {participants_range}\")\n",
    "    print(f\"Pairs per treatment per participant: {pairs_per_treatment}\")\n",
    "    print(f\"Total pairs per participant: {pairs_per_treatment * 4}\")\n",
    "    print(\"Effect sizes (log-odds):\")\n",
    "    for key, value in effect_sizes.items():\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    \n",
    "    # Run power analysis\n",
    "    results = simulate_study1_power_analysis(\n",
    "        n_participants_list=participants_range,\n",
    "        pairs_per_treatment=pairs_per_treatment,\n",
    "        effect_sizes=effect_sizes,\n",
    "        n_sim=1000,\n",
    "        alpha=0.05\n",
    "    )\n",
    "    \n",
    "    # Plot results\n",
    "    plot_study1_power_curves(results, pairs_per_treatment)\n",
    "    \n",
    "    # Find sample size requirements\n",
    "    find_study1_sample_requirements(results, pairs_per_treatment)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\n=== DETAILED RESULTS ===\")\n",
    "    for i, n in enumerate(results['n_participants']):\n",
    "        total_pairs = n * pairs_per_treatment * 4\n",
    "        print(f\"n={n:3d} ({total_pairs:4d} pairs): \"\n",
    "              f\"H1A={results['power_h1a'][i]:.3f}, \"\n",
    "              f\"H1B={results['power_h1b'][i]:.3f}, \"\n",
    "              f\"H2={results['power_h2'][i]:.3f}, \"\n",
    "              f\"H3A={results['power_h3a'][i]:.3f}, \"\n",
    "              f\"H3B={results['power_h3b'][i]:.3f}\")\n",
    "    \n",
    "    print(f\"\\n=== STUDY DESIGN SUMMARY ===\")\n",
    "    print(f\"Baseline gender bias: OR = 1.72 (moderate male preference)\")\n",
    "    print(f\"Each participant evaluates {pairs_per_treatment * 4} pairs total\")\n",
    "    print(f\"Design: 4 treatments × {pairs_per_treatment} pairs within-subjects\")\n",
    "    print(f\"Hypotheses test different aspects of AI fairness interventions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
